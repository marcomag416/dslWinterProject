{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7466206c-8197-4536-b4af-e27e9ac5386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATPLOTLIB INTERACTIVE VISUALIZATION. REMOVE (OR COMMENT) IF YOU NEED TO PRINT THE NOTEBOOK AS A PDF, SOMETIMES IT DOES NOT WORK WELL...\n",
    "#%matplotlib widget\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "from sklearn.linear_model import Lasso, LinearRegression, Ridge\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import cross_val_score, ParameterGrid\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# pd.options.display.max_rows = 9999\n",
    "pd.options.display.max_columns = 200\n",
    "\n",
    "#set initial random state\n",
    "rs = 328537\n",
    "np.random.seed(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec6199df-eefb-41d7-95f0-f05e18783d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>pmax[0]</th>\n",
       "      <th>negpmax[0]</th>\n",
       "      <th>area[0]</th>\n",
       "      <th>tmax[0]</th>\n",
       "      <th>rms[0]</th>\n",
       "      <th>pmax[1]</th>\n",
       "      <th>negpmax[1]</th>\n",
       "      <th>area[1]</th>\n",
       "      <th>tmax[1]</th>\n",
       "      <th>rms[1]</th>\n",
       "      <th>pmax[2]</th>\n",
       "      <th>negpmax[2]</th>\n",
       "      <th>area[2]</th>\n",
       "      <th>tmax[2]</th>\n",
       "      <th>rms[2]</th>\n",
       "      <th>pmax[3]</th>\n",
       "      <th>negpmax[3]</th>\n",
       "      <th>area[3]</th>\n",
       "      <th>tmax[3]</th>\n",
       "      <th>rms[3]</th>\n",
       "      <th>pmax[4]</th>\n",
       "      <th>negpmax[4]</th>\n",
       "      <th>area[4]</th>\n",
       "      <th>tmax[4]</th>\n",
       "      <th>rms[4]</th>\n",
       "      <th>pmax[5]</th>\n",
       "      <th>negpmax[5]</th>\n",
       "      <th>area[5]</th>\n",
       "      <th>tmax[5]</th>\n",
       "      <th>rms[5]</th>\n",
       "      <th>pmax[6]</th>\n",
       "      <th>negpmax[6]</th>\n",
       "      <th>area[6]</th>\n",
       "      <th>tmax[6]</th>\n",
       "      <th>rms[6]</th>\n",
       "      <th>pmax[7]</th>\n",
       "      <th>negpmax[7]</th>\n",
       "      <th>area[7]</th>\n",
       "      <th>tmax[7]</th>\n",
       "      <th>rms[7]</th>\n",
       "      <th>pmax[8]</th>\n",
       "      <th>negpmax[8]</th>\n",
       "      <th>area[8]</th>\n",
       "      <th>tmax[8]</th>\n",
       "      <th>rms[8]</th>\n",
       "      <th>pmax[9]</th>\n",
       "      <th>negpmax[9]</th>\n",
       "      <th>area[9]</th>\n",
       "      <th>tmax[9]</th>\n",
       "      <th>rms[9]</th>\n",
       "      <th>pmax[10]</th>\n",
       "      <th>negpmax[10]</th>\n",
       "      <th>area[10]</th>\n",
       "      <th>tmax[10]</th>\n",
       "      <th>rms[10]</th>\n",
       "      <th>pmax[11]</th>\n",
       "      <th>negpmax[11]</th>\n",
       "      <th>area[11]</th>\n",
       "      <th>tmax[11]</th>\n",
       "      <th>rms[11]</th>\n",
       "      <th>pmax[12]</th>\n",
       "      <th>negpmax[12]</th>\n",
       "      <th>area[12]</th>\n",
       "      <th>tmax[12]</th>\n",
       "      <th>rms[12]</th>\n",
       "      <th>pmax[13]</th>\n",
       "      <th>negpmax[13]</th>\n",
       "      <th>area[13]</th>\n",
       "      <th>tmax[13]</th>\n",
       "      <th>rms[13]</th>\n",
       "      <th>pmax[14]</th>\n",
       "      <th>negpmax[14]</th>\n",
       "      <th>area[14]</th>\n",
       "      <th>tmax[14]</th>\n",
       "      <th>rms[14]</th>\n",
       "      <th>pmax[15]</th>\n",
       "      <th>negpmax[15]</th>\n",
       "      <th>area[15]</th>\n",
       "      <th>tmax[15]</th>\n",
       "      <th>rms[15]</th>\n",
       "      <th>pmax[16]</th>\n",
       "      <th>negpmax[16]</th>\n",
       "      <th>area[16]</th>\n",
       "      <th>tmax[16]</th>\n",
       "      <th>rms[16]</th>\n",
       "      <th>pmax[17]</th>\n",
       "      <th>negpmax[17]</th>\n",
       "      <th>area[17]</th>\n",
       "      <th>tmax[17]</th>\n",
       "      <th>rms[17]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>4.066907</td>\n",
       "      <td>-17.690173</td>\n",
       "      <td>2.847932</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>2.007042</td>\n",
       "      <td>5.409161</td>\n",
       "      <td>-17.721210</td>\n",
       "      <td>4.538778</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>1.563902</td>\n",
       "      <td>6.084506</td>\n",
       "      <td>-19.892543</td>\n",
       "      <td>3.132328</td>\n",
       "      <td>72.2</td>\n",
       "      <td>1.456865</td>\n",
       "      <td>3.811328</td>\n",
       "      <td>-23.747293</td>\n",
       "      <td>3.621973</td>\n",
       "      <td>15.200000</td>\n",
       "      <td>1.531228</td>\n",
       "      <td>4.893027</td>\n",
       "      <td>-18.008972</td>\n",
       "      <td>7.215259</td>\n",
       "      <td>70.594160</td>\n",
       "      <td>0.938042</td>\n",
       "      <td>9.322305</td>\n",
       "      <td>-19.477101</td>\n",
       "      <td>5.520791</td>\n",
       "      <td>72.400000</td>\n",
       "      <td>1.412877</td>\n",
       "      <td>3.077338</td>\n",
       "      <td>-19.239130</td>\n",
       "      <td>2.079597</td>\n",
       "      <td>28.400000</td>\n",
       "      <td>1.242361</td>\n",
       "      <td>3.633856</td>\n",
       "      <td>-17.555292</td>\n",
       "      <td>1.456941</td>\n",
       "      <td>66.400000</td>\n",
       "      <td>1.521403</td>\n",
       "      <td>26.581253</td>\n",
       "      <td>-15.625539</td>\n",
       "      <td>13.374258</td>\n",
       "      <td>72.200000</td>\n",
       "      <td>1.211460</td>\n",
       "      <td>99.361264</td>\n",
       "      <td>-56.828006</td>\n",
       "      <td>48.422567</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.971254</td>\n",
       "      <td>42.068393</td>\n",
       "      <td>-19.716336</td>\n",
       "      <td>23.152819</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>1.285425</td>\n",
       "      <td>12.438458</td>\n",
       "      <td>-18.148151</td>\n",
       "      <td>7.611376</td>\n",
       "      <td>72.200000</td>\n",
       "      <td>0.904157</td>\n",
       "      <td>4.559802</td>\n",
       "      <td>-18.432141</td>\n",
       "      <td>2.288938</td>\n",
       "      <td>38.40000</td>\n",
       "      <td>0.939772</td>\n",
       "      <td>7.454877</td>\n",
       "      <td>-16.861163</td>\n",
       "      <td>4.191909</td>\n",
       "      <td>72.600000</td>\n",
       "      <td>1.184943</td>\n",
       "      <td>6.611877</td>\n",
       "      <td>-17.685799</td>\n",
       "      <td>4.884680</td>\n",
       "      <td>162.800000</td>\n",
       "      <td>1.284969</td>\n",
       "      <td>149.648736</td>\n",
       "      <td>-18.546884</td>\n",
       "      <td>146.036298</td>\n",
       "      <td>72.276594</td>\n",
       "      <td>1.196239</td>\n",
       "      <td>607.109118</td>\n",
       "      <td>-36.282996</td>\n",
       "      <td>583.899899</td>\n",
       "      <td>72.373094</td>\n",
       "      <td>0.374498</td>\n",
       "      <td>614.916861</td>\n",
       "      <td>-39.848523</td>\n",
       "      <td>591.852768</td>\n",
       "      <td>72.331028</td>\n",
       "      <td>0.405595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>5.916801</td>\n",
       "      <td>-4.717111</td>\n",
       "      <td>5.792778</td>\n",
       "      <td>79.765174</td>\n",
       "      <td>1.564535</td>\n",
       "      <td>4.414289</td>\n",
       "      <td>-4.736827</td>\n",
       "      <td>3.720435</td>\n",
       "      <td>111.875058</td>\n",
       "      <td>1.228058</td>\n",
       "      <td>4.507257</td>\n",
       "      <td>-3.787175</td>\n",
       "      <td>3.267461</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.709002</td>\n",
       "      <td>3.940369</td>\n",
       "      <td>-5.427002</td>\n",
       "      <td>3.444678</td>\n",
       "      <td>200.200000</td>\n",
       "      <td>1.172497</td>\n",
       "      <td>5.549379</td>\n",
       "      <td>-4.670676</td>\n",
       "      <td>6.666403</td>\n",
       "      <td>156.598535</td>\n",
       "      <td>1.109768</td>\n",
       "      <td>9.373914</td>\n",
       "      <td>-3.896777</td>\n",
       "      <td>6.821667</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>1.489011</td>\n",
       "      <td>5.424356</td>\n",
       "      <td>-4.675986</td>\n",
       "      <td>5.481520</td>\n",
       "      <td>70.600000</td>\n",
       "      <td>1.684811</td>\n",
       "      <td>5.126883</td>\n",
       "      <td>-4.857126</td>\n",
       "      <td>4.561109</td>\n",
       "      <td>181.200000</td>\n",
       "      <td>1.356535</td>\n",
       "      <td>27.797015</td>\n",
       "      <td>-11.742902</td>\n",
       "      <td>14.334657</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>1.248869</td>\n",
       "      <td>96.062561</td>\n",
       "      <td>-58.803436</td>\n",
       "      <td>47.559857</td>\n",
       "      <td>70.8</td>\n",
       "      <td>1.646606</td>\n",
       "      <td>38.690210</td>\n",
       "      <td>-19.613623</td>\n",
       "      <td>20.574321</td>\n",
       "      <td>70.800000</td>\n",
       "      <td>1.236410</td>\n",
       "      <td>12.326212</td>\n",
       "      <td>-5.670920</td>\n",
       "      <td>8.025536</td>\n",
       "      <td>119.600000</td>\n",
       "      <td>1.201039</td>\n",
       "      <td>15.498431</td>\n",
       "      <td>-6.770750</td>\n",
       "      <td>11.107231</td>\n",
       "      <td>119.84105</td>\n",
       "      <td>1.483650</td>\n",
       "      <td>18.472514</td>\n",
       "      <td>-3.372324</td>\n",
       "      <td>16.620582</td>\n",
       "      <td>119.812512</td>\n",
       "      <td>1.578009</td>\n",
       "      <td>13.802252</td>\n",
       "      <td>-5.154840</td>\n",
       "      <td>8.758870</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>1.093953</td>\n",
       "      <td>148.942977</td>\n",
       "      <td>-4.697864</td>\n",
       "      <td>171.081604</td>\n",
       "      <td>71.065221</td>\n",
       "      <td>1.534433</td>\n",
       "      <td>630.348007</td>\n",
       "      <td>-39.715988</td>\n",
       "      <td>580.042799</td>\n",
       "      <td>71.029155</td>\n",
       "      <td>0.403258</td>\n",
       "      <td>624.950701</td>\n",
       "      <td>-41.266681</td>\n",
       "      <td>586.569646</td>\n",
       "      <td>71.089058</td>\n",
       "      <td>0.405890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>4.286652</td>\n",
       "      <td>-5.316132</td>\n",
       "      <td>2.356390</td>\n",
       "      <td>74.600000</td>\n",
       "      <td>1.404622</td>\n",
       "      <td>4.567191</td>\n",
       "      <td>-5.985437</td>\n",
       "      <td>3.490490</td>\n",
       "      <td>107.800000</td>\n",
       "      <td>1.015408</td>\n",
       "      <td>5.384155</td>\n",
       "      <td>-3.948853</td>\n",
       "      <td>2.929150</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.373336</td>\n",
       "      <td>4.903412</td>\n",
       "      <td>-4.559235</td>\n",
       "      <td>1.223700</td>\n",
       "      <td>204.600000</td>\n",
       "      <td>1.508628</td>\n",
       "      <td>3.795407</td>\n",
       "      <td>-4.761539</td>\n",
       "      <td>1.397493</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>1.121483</td>\n",
       "      <td>7.499896</td>\n",
       "      <td>-5.343427</td>\n",
       "      <td>7.260222</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>1.547936</td>\n",
       "      <td>5.846233</td>\n",
       "      <td>-5.021164</td>\n",
       "      <td>6.073777</td>\n",
       "      <td>71.541859</td>\n",
       "      <td>1.529981</td>\n",
       "      <td>4.284341</td>\n",
       "      <td>-5.049019</td>\n",
       "      <td>3.330127</td>\n",
       "      <td>17.229922</td>\n",
       "      <td>1.636174</td>\n",
       "      <td>23.163651</td>\n",
       "      <td>-11.581955</td>\n",
       "      <td>11.901321</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>1.712700</td>\n",
       "      <td>93.767398</td>\n",
       "      <td>-62.801328</td>\n",
       "      <td>46.121189</td>\n",
       "      <td>71.6</td>\n",
       "      <td>1.509499</td>\n",
       "      <td>40.337067</td>\n",
       "      <td>-23.637970</td>\n",
       "      <td>19.456946</td>\n",
       "      <td>71.600000</td>\n",
       "      <td>1.973803</td>\n",
       "      <td>9.253250</td>\n",
       "      <td>-4.282883</td>\n",
       "      <td>4.517316</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>1.995394</td>\n",
       "      <td>4.168692</td>\n",
       "      <td>-4.282668</td>\n",
       "      <td>2.504671</td>\n",
       "      <td>141.60000</td>\n",
       "      <td>2.004948</td>\n",
       "      <td>7.336668</td>\n",
       "      <td>-5.742383</td>\n",
       "      <td>11.792258</td>\n",
       "      <td>71.908212</td>\n",
       "      <td>1.333036</td>\n",
       "      <td>5.940039</td>\n",
       "      <td>-3.860550</td>\n",
       "      <td>5.340140</td>\n",
       "      <td>6.614830</td>\n",
       "      <td>1.183951</td>\n",
       "      <td>153.494632</td>\n",
       "      <td>-4.584915</td>\n",
       "      <td>137.502422</td>\n",
       "      <td>71.869933</td>\n",
       "      <td>1.010175</td>\n",
       "      <td>613.880342</td>\n",
       "      <td>-40.679678</td>\n",
       "      <td>580.407491</td>\n",
       "      <td>71.892264</td>\n",
       "      <td>0.568777</td>\n",
       "      <td>596.437125</td>\n",
       "      <td>-42.712286</td>\n",
       "      <td>574.091695</td>\n",
       "      <td>71.943934</td>\n",
       "      <td>0.498019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>4.003635</td>\n",
       "      <td>-4.617459</td>\n",
       "      <td>2.189005</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>1.512162</td>\n",
       "      <td>5.019058</td>\n",
       "      <td>-4.229949</td>\n",
       "      <td>6.786200</td>\n",
       "      <td>175.600000</td>\n",
       "      <td>1.350620</td>\n",
       "      <td>4.165598</td>\n",
       "      <td>-5.576041</td>\n",
       "      <td>1.544370</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.115078</td>\n",
       "      <td>3.791672</td>\n",
       "      <td>-4.981216</td>\n",
       "      <td>2.985681</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>1.374108</td>\n",
       "      <td>4.848719</td>\n",
       "      <td>-3.985501</td>\n",
       "      <td>5.184150</td>\n",
       "      <td>197.725932</td>\n",
       "      <td>1.849099</td>\n",
       "      <td>10.422260</td>\n",
       "      <td>-4.916791</td>\n",
       "      <td>5.480527</td>\n",
       "      <td>72.400000</td>\n",
       "      <td>0.809550</td>\n",
       "      <td>5.157927</td>\n",
       "      <td>-3.594675</td>\n",
       "      <td>9.393185</td>\n",
       "      <td>72.081513</td>\n",
       "      <td>1.633162</td>\n",
       "      <td>2.999829</td>\n",
       "      <td>-6.250171</td>\n",
       "      <td>2.250264</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.737832</td>\n",
       "      <td>26.592899</td>\n",
       "      <td>-10.409299</td>\n",
       "      <td>12.231570</td>\n",
       "      <td>72.200000</td>\n",
       "      <td>0.825131</td>\n",
       "      <td>89.620438</td>\n",
       "      <td>-62.658493</td>\n",
       "      <td>48.821906</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.945644</td>\n",
       "      <td>37.796774</td>\n",
       "      <td>-21.114725</td>\n",
       "      <td>20.897897</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>1.224526</td>\n",
       "      <td>10.900876</td>\n",
       "      <td>-5.595096</td>\n",
       "      <td>5.927390</td>\n",
       "      <td>72.200000</td>\n",
       "      <td>1.491610</td>\n",
       "      <td>3.521313</td>\n",
       "      <td>-5.788109</td>\n",
       "      <td>1.350378</td>\n",
       "      <td>70.60000</td>\n",
       "      <td>1.019475</td>\n",
       "      <td>8.450671</td>\n",
       "      <td>-6.342114</td>\n",
       "      <td>4.496741</td>\n",
       "      <td>72.600000</td>\n",
       "      <td>1.945065</td>\n",
       "      <td>6.434910</td>\n",
       "      <td>-5.576315</td>\n",
       "      <td>15.789638</td>\n",
       "      <td>72.195420</td>\n",
       "      <td>1.738998</td>\n",
       "      <td>151.859889</td>\n",
       "      <td>-4.744748</td>\n",
       "      <td>135.724871</td>\n",
       "      <td>72.262946</td>\n",
       "      <td>1.283015</td>\n",
       "      <td>600.714957</td>\n",
       "      <td>-43.206601</td>\n",
       "      <td>579.882635</td>\n",
       "      <td>72.357388</td>\n",
       "      <td>0.255483</td>\n",
       "      <td>591.763739</td>\n",
       "      <td>-50.681940</td>\n",
       "      <td>584.099483</td>\n",
       "      <td>72.333282</td>\n",
       "      <td>0.336454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>4.448146</td>\n",
       "      <td>-4.848743</td>\n",
       "      <td>3.997002</td>\n",
       "      <td>196.667482</td>\n",
       "      <td>1.101113</td>\n",
       "      <td>3.250262</td>\n",
       "      <td>-5.783587</td>\n",
       "      <td>2.449456</td>\n",
       "      <td>159.800000</td>\n",
       "      <td>0.759515</td>\n",
       "      <td>4.736023</td>\n",
       "      <td>-5.137939</td>\n",
       "      <td>4.211047</td>\n",
       "      <td>71.2</td>\n",
       "      <td>1.237268</td>\n",
       "      <td>5.123048</td>\n",
       "      <td>-4.447104</td>\n",
       "      <td>4.377708</td>\n",
       "      <td>71.357237</td>\n",
       "      <td>1.417505</td>\n",
       "      <td>3.026709</td>\n",
       "      <td>-6.137964</td>\n",
       "      <td>1.423594</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>1.474896</td>\n",
       "      <td>12.557806</td>\n",
       "      <td>-4.582629</td>\n",
       "      <td>9.222847</td>\n",
       "      <td>71.160201</td>\n",
       "      <td>1.814520</td>\n",
       "      <td>6.115046</td>\n",
       "      <td>-4.172168</td>\n",
       "      <td>4.218594</td>\n",
       "      <td>70.759682</td>\n",
       "      <td>1.794109</td>\n",
       "      <td>4.456955</td>\n",
       "      <td>-4.346878</td>\n",
       "      <td>2.842813</td>\n",
       "      <td>142.200000</td>\n",
       "      <td>0.801273</td>\n",
       "      <td>25.261710</td>\n",
       "      <td>-10.298044</td>\n",
       "      <td>11.949759</td>\n",
       "      <td>71.200000</td>\n",
       "      <td>1.627493</td>\n",
       "      <td>106.109430</td>\n",
       "      <td>-68.653479</td>\n",
       "      <td>49.846171</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.471771</td>\n",
       "      <td>42.202023</td>\n",
       "      <td>-20.666324</td>\n",
       "      <td>21.795638</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>1.604495</td>\n",
       "      <td>13.956659</td>\n",
       "      <td>-5.728705</td>\n",
       "      <td>7.386077</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>1.318873</td>\n",
       "      <td>3.991907</td>\n",
       "      <td>-5.890051</td>\n",
       "      <td>3.002041</td>\n",
       "      <td>109.20000</td>\n",
       "      <td>1.384048</td>\n",
       "      <td>8.721952</td>\n",
       "      <td>-4.396436</td>\n",
       "      <td>9.127136</td>\n",
       "      <td>71.411535</td>\n",
       "      <td>1.513988</td>\n",
       "      <td>4.483080</td>\n",
       "      <td>-5.361823</td>\n",
       "      <td>3.366542</td>\n",
       "      <td>160.185705</td>\n",
       "      <td>1.323621</td>\n",
       "      <td>137.139115</td>\n",
       "      <td>-5.357361</td>\n",
       "      <td>147.372754</td>\n",
       "      <td>71.212440</td>\n",
       "      <td>1.480449</td>\n",
       "      <td>609.723785</td>\n",
       "      <td>-43.570892</td>\n",
       "      <td>590.156125</td>\n",
       "      <td>71.249130</td>\n",
       "      <td>0.413855</td>\n",
       "      <td>606.917023</td>\n",
       "      <td>-49.923819</td>\n",
       "      <td>584.316142</td>\n",
       "      <td>71.242904</td>\n",
       "      <td>0.293824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385495</th>\n",
       "      <td>600.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>5.051422</td>\n",
       "      <td>-3.872162</td>\n",
       "      <td>14.537390</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.103550</td>\n",
       "      <td>49.819376</td>\n",
       "      <td>-26.266623</td>\n",
       "      <td>24.781403</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>1.021450</td>\n",
       "      <td>55.651440</td>\n",
       "      <td>-29.947864</td>\n",
       "      <td>28.621582</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.782512</td>\n",
       "      <td>63.119604</td>\n",
       "      <td>-36.910852</td>\n",
       "      <td>32.034504</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>1.829785</td>\n",
       "      <td>11.942999</td>\n",
       "      <td>-3.202997</td>\n",
       "      <td>7.329171</td>\n",
       "      <td>71.200000</td>\n",
       "      <td>1.498869</td>\n",
       "      <td>12.878128</td>\n",
       "      <td>-5.162094</td>\n",
       "      <td>7.175116</td>\n",
       "      <td>71.200000</td>\n",
       "      <td>1.296357</td>\n",
       "      <td>4.604367</td>\n",
       "      <td>-4.497623</td>\n",
       "      <td>3.776117</td>\n",
       "      <td>89.200000</td>\n",
       "      <td>1.556523</td>\n",
       "      <td>5.052438</td>\n",
       "      <td>-5.660696</td>\n",
       "      <td>1.969392</td>\n",
       "      <td>26.200000</td>\n",
       "      <td>2.248684</td>\n",
       "      <td>4.668842</td>\n",
       "      <td>-4.807355</td>\n",
       "      <td>3.696760</td>\n",
       "      <td>193.200000</td>\n",
       "      <td>0.876277</td>\n",
       "      <td>3.324582</td>\n",
       "      <td>-4.966765</td>\n",
       "      <td>1.712936</td>\n",
       "      <td>93.2</td>\n",
       "      <td>0.906276</td>\n",
       "      <td>5.018600</td>\n",
       "      <td>-4.641771</td>\n",
       "      <td>1.715207</td>\n",
       "      <td>71.400000</td>\n",
       "      <td>1.467989</td>\n",
       "      <td>5.526794</td>\n",
       "      <td>-6.992345</td>\n",
       "      <td>1.990222</td>\n",
       "      <td>204.400000</td>\n",
       "      <td>1.061959</td>\n",
       "      <td>3.577979</td>\n",
       "      <td>-5.627954</td>\n",
       "      <td>2.159707</td>\n",
       "      <td>53.80000</td>\n",
       "      <td>0.767079</td>\n",
       "      <td>19.454065</td>\n",
       "      <td>-7.531409</td>\n",
       "      <td>10.650762</td>\n",
       "      <td>71.400000</td>\n",
       "      <td>0.964490</td>\n",
       "      <td>5.842563</td>\n",
       "      <td>-4.147369</td>\n",
       "      <td>4.551567</td>\n",
       "      <td>71.200000</td>\n",
       "      <td>1.681396</td>\n",
       "      <td>131.786591</td>\n",
       "      <td>-4.857419</td>\n",
       "      <td>153.707394</td>\n",
       "      <td>71.415674</td>\n",
       "      <td>1.932267</td>\n",
       "      <td>581.954264</td>\n",
       "      <td>-39.634247</td>\n",
       "      <td>580.419676</td>\n",
       "      <td>71.167754</td>\n",
       "      <td>0.714250</td>\n",
       "      <td>614.629732</td>\n",
       "      <td>-47.182980</td>\n",
       "      <td>594.565758</td>\n",
       "      <td>71.359798</td>\n",
       "      <td>0.345872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385496</th>\n",
       "      <td>600.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>4.067664</td>\n",
       "      <td>-5.534358</td>\n",
       "      <td>2.011714</td>\n",
       "      <td>40.200000</td>\n",
       "      <td>1.895393</td>\n",
       "      <td>51.016495</td>\n",
       "      <td>-26.138474</td>\n",
       "      <td>27.090894</td>\n",
       "      <td>71.400000</td>\n",
       "      <td>1.570939</td>\n",
       "      <td>58.084024</td>\n",
       "      <td>-34.662131</td>\n",
       "      <td>28.435582</td>\n",
       "      <td>71.4</td>\n",
       "      <td>1.390139</td>\n",
       "      <td>59.971158</td>\n",
       "      <td>-37.721255</td>\n",
       "      <td>32.350015</td>\n",
       "      <td>71.400000</td>\n",
       "      <td>1.316458</td>\n",
       "      <td>11.555255</td>\n",
       "      <td>-5.173907</td>\n",
       "      <td>8.177859</td>\n",
       "      <td>71.461099</td>\n",
       "      <td>1.490002</td>\n",
       "      <td>9.729486</td>\n",
       "      <td>-5.582098</td>\n",
       "      <td>5.111370</td>\n",
       "      <td>71.600000</td>\n",
       "      <td>1.563036</td>\n",
       "      <td>4.075574</td>\n",
       "      <td>-4.323596</td>\n",
       "      <td>3.377163</td>\n",
       "      <td>188.800000</td>\n",
       "      <td>1.112393</td>\n",
       "      <td>4.845581</td>\n",
       "      <td>-3.837952</td>\n",
       "      <td>2.791040</td>\n",
       "      <td>171.200000</td>\n",
       "      <td>1.511234</td>\n",
       "      <td>14.101810</td>\n",
       "      <td>-4.986447</td>\n",
       "      <td>11.568833</td>\n",
       "      <td>72.200000</td>\n",
       "      <td>1.941815</td>\n",
       "      <td>12.819989</td>\n",
       "      <td>-4.160602</td>\n",
       "      <td>6.684895</td>\n",
       "      <td>72.2</td>\n",
       "      <td>1.675671</td>\n",
       "      <td>12.100403</td>\n",
       "      <td>-4.664246</td>\n",
       "      <td>8.123401</td>\n",
       "      <td>72.200000</td>\n",
       "      <td>1.856407</td>\n",
       "      <td>15.208563</td>\n",
       "      <td>-5.161127</td>\n",
       "      <td>11.758268</td>\n",
       "      <td>72.200000</td>\n",
       "      <td>1.330986</td>\n",
       "      <td>15.737668</td>\n",
       "      <td>-4.732547</td>\n",
       "      <td>7.565947</td>\n",
       "      <td>72.20000</td>\n",
       "      <td>1.717499</td>\n",
       "      <td>17.604636</td>\n",
       "      <td>-5.505725</td>\n",
       "      <td>12.827195</td>\n",
       "      <td>71.500314</td>\n",
       "      <td>1.632497</td>\n",
       "      <td>11.819031</td>\n",
       "      <td>-5.125480</td>\n",
       "      <td>4.505713</td>\n",
       "      <td>72.400000</td>\n",
       "      <td>1.227755</td>\n",
       "      <td>122.000994</td>\n",
       "      <td>-3.520840</td>\n",
       "      <td>162.981252</td>\n",
       "      <td>71.598409</td>\n",
       "      <td>1.305790</td>\n",
       "      <td>591.334030</td>\n",
       "      <td>-40.229095</td>\n",
       "      <td>589.105579</td>\n",
       "      <td>71.562414</td>\n",
       "      <td>0.325978</td>\n",
       "      <td>589.602095</td>\n",
       "      <td>-49.995053</td>\n",
       "      <td>588.799525</td>\n",
       "      <td>71.539605</td>\n",
       "      <td>0.318873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385497</th>\n",
       "      <td>600.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>4.243555</td>\n",
       "      <td>-5.801462</td>\n",
       "      <td>3.199481</td>\n",
       "      <td>150.891763</td>\n",
       "      <td>1.248541</td>\n",
       "      <td>46.661682</td>\n",
       "      <td>-30.943115</td>\n",
       "      <td>24.980347</td>\n",
       "      <td>71.200000</td>\n",
       "      <td>1.255832</td>\n",
       "      <td>61.840103</td>\n",
       "      <td>-35.670273</td>\n",
       "      <td>30.500351</td>\n",
       "      <td>71.2</td>\n",
       "      <td>1.056464</td>\n",
       "      <td>73.850089</td>\n",
       "      <td>-38.344370</td>\n",
       "      <td>33.456961</td>\n",
       "      <td>71.200000</td>\n",
       "      <td>1.874057</td>\n",
       "      <td>16.884897</td>\n",
       "      <td>-5.173453</td>\n",
       "      <td>8.721312</td>\n",
       "      <td>71.400000</td>\n",
       "      <td>1.186608</td>\n",
       "      <td>13.104062</td>\n",
       "      <td>-4.633670</td>\n",
       "      <td>7.310897</td>\n",
       "      <td>71.400000</td>\n",
       "      <td>1.125781</td>\n",
       "      <td>6.381778</td>\n",
       "      <td>-5.319577</td>\n",
       "      <td>3.605681</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>1.029841</td>\n",
       "      <td>5.219055</td>\n",
       "      <td>-3.618164</td>\n",
       "      <td>6.078650</td>\n",
       "      <td>176.275387</td>\n",
       "      <td>1.619186</td>\n",
       "      <td>7.160672</td>\n",
       "      <td>-3.944553</td>\n",
       "      <td>4.267343</td>\n",
       "      <td>132.800000</td>\n",
       "      <td>1.612187</td>\n",
       "      <td>3.859982</td>\n",
       "      <td>-5.145389</td>\n",
       "      <td>2.331159</td>\n",
       "      <td>76.4</td>\n",
       "      <td>1.267967</td>\n",
       "      <td>6.587385</td>\n",
       "      <td>-3.648233</td>\n",
       "      <td>9.381399</td>\n",
       "      <td>71.247274</td>\n",
       "      <td>1.655136</td>\n",
       "      <td>5.343299</td>\n",
       "      <td>-4.516763</td>\n",
       "      <td>4.862441</td>\n",
       "      <td>71.576952</td>\n",
       "      <td>2.044186</td>\n",
       "      <td>5.385049</td>\n",
       "      <td>-4.829733</td>\n",
       "      <td>3.039965</td>\n",
       "      <td>127.00000</td>\n",
       "      <td>1.266236</td>\n",
       "      <td>20.783524</td>\n",
       "      <td>-6.318405</td>\n",
       "      <td>13.981320</td>\n",
       "      <td>71.600000</td>\n",
       "      <td>1.944626</td>\n",
       "      <td>10.120659</td>\n",
       "      <td>-3.479907</td>\n",
       "      <td>11.049597</td>\n",
       "      <td>71.373814</td>\n",
       "      <td>1.273724</td>\n",
       "      <td>131.856155</td>\n",
       "      <td>-5.187308</td>\n",
       "      <td>151.267330</td>\n",
       "      <td>71.605585</td>\n",
       "      <td>2.086888</td>\n",
       "      <td>619.698505</td>\n",
       "      <td>-46.600293</td>\n",
       "      <td>582.079851</td>\n",
       "      <td>71.420761</td>\n",
       "      <td>0.430833</td>\n",
       "      <td>610.999390</td>\n",
       "      <td>-43.620535</td>\n",
       "      <td>589.163170</td>\n",
       "      <td>71.569655</td>\n",
       "      <td>0.301635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385498</th>\n",
       "      <td>600.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>14.552444</td>\n",
       "      <td>-5.017258</td>\n",
       "      <td>6.367075</td>\n",
       "      <td>72.200000</td>\n",
       "      <td>1.215713</td>\n",
       "      <td>46.515765</td>\n",
       "      <td>-22.520367</td>\n",
       "      <td>33.163073</td>\n",
       "      <td>71.400000</td>\n",
       "      <td>1.465443</td>\n",
       "      <td>49.772070</td>\n",
       "      <td>-33.298181</td>\n",
       "      <td>27.110076</td>\n",
       "      <td>71.2</td>\n",
       "      <td>1.198712</td>\n",
       "      <td>59.277927</td>\n",
       "      <td>-36.103391</td>\n",
       "      <td>31.008201</td>\n",
       "      <td>71.200000</td>\n",
       "      <td>2.139997</td>\n",
       "      <td>12.191660</td>\n",
       "      <td>-4.629693</td>\n",
       "      <td>5.569931</td>\n",
       "      <td>71.400000</td>\n",
       "      <td>1.636094</td>\n",
       "      <td>11.139015</td>\n",
       "      <td>-4.630464</td>\n",
       "      <td>15.777069</td>\n",
       "      <td>71.364422</td>\n",
       "      <td>1.576356</td>\n",
       "      <td>14.606870</td>\n",
       "      <td>-4.281985</td>\n",
       "      <td>8.902606</td>\n",
       "      <td>72.200000</td>\n",
       "      <td>2.050272</td>\n",
       "      <td>15.296118</td>\n",
       "      <td>-3.948083</td>\n",
       "      <td>7.470391</td>\n",
       "      <td>72.200000</td>\n",
       "      <td>1.042840</td>\n",
       "      <td>16.477707</td>\n",
       "      <td>-4.348218</td>\n",
       "      <td>6.246851</td>\n",
       "      <td>72.158232</td>\n",
       "      <td>1.794087</td>\n",
       "      <td>11.385178</td>\n",
       "      <td>-2.968319</td>\n",
       "      <td>5.846973</td>\n",
       "      <td>72.2</td>\n",
       "      <td>1.181766</td>\n",
       "      <td>13.214905</td>\n",
       "      <td>-4.522888</td>\n",
       "      <td>8.463049</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>1.647129</td>\n",
       "      <td>13.605057</td>\n",
       "      <td>-5.050461</td>\n",
       "      <td>9.017706</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>2.052866</td>\n",
       "      <td>15.326770</td>\n",
       "      <td>-4.139905</td>\n",
       "      <td>16.555281</td>\n",
       "      <td>72.20000</td>\n",
       "      <td>0.985935</td>\n",
       "      <td>14.048267</td>\n",
       "      <td>-6.915601</td>\n",
       "      <td>11.846003</td>\n",
       "      <td>71.600000</td>\n",
       "      <td>1.286150</td>\n",
       "      <td>10.754880</td>\n",
       "      <td>-5.030399</td>\n",
       "      <td>7.560762</td>\n",
       "      <td>71.200000</td>\n",
       "      <td>1.053635</td>\n",
       "      <td>122.657732</td>\n",
       "      <td>-4.574358</td>\n",
       "      <td>161.842151</td>\n",
       "      <td>71.501886</td>\n",
       "      <td>0.932597</td>\n",
       "      <td>597.935632</td>\n",
       "      <td>-43.848615</td>\n",
       "      <td>589.201047</td>\n",
       "      <td>71.426835</td>\n",
       "      <td>0.474301</td>\n",
       "      <td>611.263138</td>\n",
       "      <td>-49.387009</td>\n",
       "      <td>587.916994</td>\n",
       "      <td>71.466307</td>\n",
       "      <td>0.408242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385499</th>\n",
       "      <td>600.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>4.203323</td>\n",
       "      <td>-21.787461</td>\n",
       "      <td>3.241678</td>\n",
       "      <td>65.200000</td>\n",
       "      <td>1.780837</td>\n",
       "      <td>53.988147</td>\n",
       "      <td>-26.616895</td>\n",
       "      <td>31.294717</td>\n",
       "      <td>71.600000</td>\n",
       "      <td>1.207622</td>\n",
       "      <td>59.774219</td>\n",
       "      <td>-31.891431</td>\n",
       "      <td>27.387000</td>\n",
       "      <td>71.6</td>\n",
       "      <td>1.264768</td>\n",
       "      <td>64.351324</td>\n",
       "      <td>-37.448969</td>\n",
       "      <td>30.591620</td>\n",
       "      <td>71.600000</td>\n",
       "      <td>1.146192</td>\n",
       "      <td>14.529691</td>\n",
       "      <td>-17.717380</td>\n",
       "      <td>9.240368</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>0.980459</td>\n",
       "      <td>13.715833</td>\n",
       "      <td>-18.863248</td>\n",
       "      <td>10.317190</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>1.542316</td>\n",
       "      <td>4.348273</td>\n",
       "      <td>-21.837317</td>\n",
       "      <td>3.877599</td>\n",
       "      <td>71.600000</td>\n",
       "      <td>1.789487</td>\n",
       "      <td>4.794330</td>\n",
       "      <td>-16.178510</td>\n",
       "      <td>1.785699</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>1.394616</td>\n",
       "      <td>4.402023</td>\n",
       "      <td>-18.913599</td>\n",
       "      <td>3.972903</td>\n",
       "      <td>62.400000</td>\n",
       "      <td>1.207466</td>\n",
       "      <td>3.848242</td>\n",
       "      <td>-20.433275</td>\n",
       "      <td>2.189797</td>\n",
       "      <td>130.2</td>\n",
       "      <td>1.062997</td>\n",
       "      <td>4.959647</td>\n",
       "      <td>-21.246221</td>\n",
       "      <td>3.000378</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>1.761634</td>\n",
       "      <td>6.934341</td>\n",
       "      <td>-15.145020</td>\n",
       "      <td>18.547925</td>\n",
       "      <td>71.861420</td>\n",
       "      <td>1.224573</td>\n",
       "      <td>5.624060</td>\n",
       "      <td>-18.254765</td>\n",
       "      <td>2.775803</td>\n",
       "      <td>167.40000</td>\n",
       "      <td>2.039344</td>\n",
       "      <td>21.256503</td>\n",
       "      <td>-17.559171</td>\n",
       "      <td>15.069589</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.734442</td>\n",
       "      <td>6.895911</td>\n",
       "      <td>-20.049325</td>\n",
       "      <td>3.515742</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>1.589978</td>\n",
       "      <td>119.050219</td>\n",
       "      <td>-22.519223</td>\n",
       "      <td>151.665894</td>\n",
       "      <td>72.067806</td>\n",
       "      <td>1.593781</td>\n",
       "      <td>605.837434</td>\n",
       "      <td>-43.600342</td>\n",
       "      <td>583.723657</td>\n",
       "      <td>71.814597</td>\n",
       "      <td>0.509508</td>\n",
       "      <td>581.580222</td>\n",
       "      <td>-51.947507</td>\n",
       "      <td>582.576141</td>\n",
       "      <td>72.015844</td>\n",
       "      <td>0.354110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>385500 rows Ã— 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x      y    pmax[0]  negpmax[0]    area[0]     tmax[0]    rms[0]  \\\n",
       "0       200.0  200.0   4.066907  -17.690173   2.847932    0.600000  2.007042   \n",
       "1       200.0  200.0   5.916801   -4.717111   5.792778   79.765174  1.564535   \n",
       "2       200.0  200.0   4.286652   -5.316132   2.356390   74.600000  1.404622   \n",
       "3       200.0  200.0   4.003635   -4.617459   2.189005   43.000000  1.512162   \n",
       "4       200.0  200.0   4.448146   -4.848743   3.997002  196.667482  1.101113   \n",
       "...       ...    ...        ...         ...        ...         ...       ...   \n",
       "385495  600.0  595.0   5.051422   -3.872162  14.537390   32.000000  1.103550   \n",
       "385496  600.0  595.0   4.067664   -5.534358   2.011714   40.200000  1.895393   \n",
       "385497  600.0  595.0   4.243555   -5.801462   3.199481  150.891763  1.248541   \n",
       "385498  600.0  595.0  14.552444   -5.017258   6.367075   72.200000  1.215713   \n",
       "385499  600.0  595.0   4.203323  -21.787461   3.241678   65.200000  1.780837   \n",
       "\n",
       "          pmax[1]  negpmax[1]    area[1]     tmax[1]    rms[1]    pmax[2]  \\\n",
       "0        5.409161  -17.721210   4.538778   22.600000  1.563902   6.084506   \n",
       "1        4.414289   -4.736827   3.720435  111.875058  1.228058   4.507257   \n",
       "2        4.567191   -5.985437   3.490490  107.800000  1.015408   5.384155   \n",
       "3        5.019058   -4.229949   6.786200  175.600000  1.350620   4.165598   \n",
       "4        3.250262   -5.783587   2.449456  159.800000  0.759515   4.736023   \n",
       "...           ...         ...        ...         ...       ...        ...   \n",
       "385495  49.819376  -26.266623  24.781403   71.000000  1.021450  55.651440   \n",
       "385496  51.016495  -26.138474  27.090894   71.400000  1.570939  58.084024   \n",
       "385497  46.661682  -30.943115  24.980347   71.200000  1.255832  61.840103   \n",
       "385498  46.515765  -22.520367  33.163073   71.400000  1.465443  49.772070   \n",
       "385499  53.988147  -26.616895  31.294717   71.600000  1.207622  59.774219   \n",
       "\n",
       "        negpmax[2]    area[2]  tmax[2]    rms[2]    pmax[3]  negpmax[3]  \\\n",
       "0       -19.892543   3.132328     72.2  1.456865   3.811328  -23.747293   \n",
       "1        -3.787175   3.267461     55.0  1.709002   3.940369   -5.427002   \n",
       "2        -3.948853   2.929150     28.0  1.373336   4.903412   -4.559235   \n",
       "3        -5.576041   1.544370     14.0  1.115078   3.791672   -4.981216   \n",
       "4        -5.137939   4.211047     71.2  1.237268   5.123048   -4.447104   \n",
       "...            ...        ...      ...       ...        ...         ...   \n",
       "385495  -29.947864  28.621582     71.0  0.782512  63.119604  -36.910852   \n",
       "385496  -34.662131  28.435582     71.4  1.390139  59.971158  -37.721255   \n",
       "385497  -35.670273  30.500351     71.2  1.056464  73.850089  -38.344370   \n",
       "385498  -33.298181  27.110076     71.2  1.198712  59.277927  -36.103391   \n",
       "385499  -31.891431  27.387000     71.6  1.264768  64.351324  -37.448969   \n",
       "\n",
       "          area[3]     tmax[3]    rms[3]    pmax[4]  negpmax[4]   area[4]  \\\n",
       "0        3.621973   15.200000  1.531228   4.893027  -18.008972  7.215259   \n",
       "1        3.444678  200.200000  1.172497   5.549379   -4.670676  6.666403   \n",
       "2        1.223700  204.600000  1.508628   3.795407   -4.761539  1.397493   \n",
       "3        2.985681  104.000000  1.374108   4.848719   -3.985501  5.184150   \n",
       "4        4.377708   71.357237  1.417505   3.026709   -6.137964  1.423594   \n",
       "...           ...         ...       ...        ...         ...       ...   \n",
       "385495  32.034504   71.000000  1.829785  11.942999   -3.202997  7.329171   \n",
       "385496  32.350015   71.400000  1.316458  11.555255   -5.173907  8.177859   \n",
       "385497  33.456961   71.200000  1.874057  16.884897   -5.173453  8.721312   \n",
       "385498  31.008201   71.200000  2.139997  12.191660   -4.629693  5.569931   \n",
       "385499  30.591620   71.600000  1.146192  14.529691  -17.717380  9.240368   \n",
       "\n",
       "           tmax[4]    rms[4]    pmax[5]  negpmax[5]    area[5]    tmax[5]  \\\n",
       "0        70.594160  0.938042   9.322305  -19.477101   5.520791  72.400000   \n",
       "1       156.598535  1.109768   9.373914   -3.896777   6.821667  71.000000   \n",
       "2        71.800000  1.121483   7.499896   -5.343427   7.260222  71.800000   \n",
       "3       197.725932  1.849099  10.422260   -4.916791   5.480527  72.400000   \n",
       "4         2.600000  1.474896  12.557806   -4.582629   9.222847  71.160201   \n",
       "...            ...       ...        ...         ...        ...        ...   \n",
       "385495   71.200000  1.498869  12.878128   -5.162094   7.175116  71.200000   \n",
       "385496   71.461099  1.490002   9.729486   -5.582098   5.111370  71.600000   \n",
       "385497   71.400000  1.186608  13.104062   -4.633670   7.310897  71.400000   \n",
       "385498   71.400000  1.636094  11.139015   -4.630464  15.777069  71.364422   \n",
       "385499   71.800000  0.980459  13.715833  -18.863248  10.317190  71.800000   \n",
       "\n",
       "          rms[5]    pmax[6]  negpmax[6]   area[6]     tmax[6]    rms[6]  \\\n",
       "0       1.412877   3.077338  -19.239130  2.079597   28.400000  1.242361   \n",
       "1       1.489011   5.424356   -4.675986  5.481520   70.600000  1.684811   \n",
       "2       1.547936   5.846233   -5.021164  6.073777   71.541859  1.529981   \n",
       "3       0.809550   5.157927   -3.594675  9.393185   72.081513  1.633162   \n",
       "4       1.814520   6.115046   -4.172168  4.218594   70.759682  1.794109   \n",
       "...          ...        ...         ...       ...         ...       ...   \n",
       "385495  1.296357   4.604367   -4.497623  3.776117   89.200000  1.556523   \n",
       "385496  1.563036   4.075574   -4.323596  3.377163  188.800000  1.112393   \n",
       "385497  1.125781   6.381778   -5.319577  3.605681   71.000000  1.029841   \n",
       "385498  1.576356  14.606870   -4.281985  8.902606   72.200000  2.050272   \n",
       "385499  1.542316   4.348273  -21.837317  3.877599   71.600000  1.789487   \n",
       "\n",
       "          pmax[7]  negpmax[7]   area[7]     tmax[7]    rms[7]    pmax[8]  \\\n",
       "0        3.633856  -17.555292  1.456941   66.400000  1.521403  26.581253   \n",
       "1        5.126883   -4.857126  4.561109  181.200000  1.356535  27.797015   \n",
       "2        4.284341   -5.049019  3.330127   17.229922  1.636174  23.163651   \n",
       "3        2.999829   -6.250171  2.250264    1.600000  1.737832  26.592899   \n",
       "4        4.456955   -4.346878  2.842813  142.200000  0.801273  25.261710   \n",
       "...           ...         ...       ...         ...       ...        ...   \n",
       "385495   5.052438   -5.660696  1.969392   26.200000  2.248684   4.668842   \n",
       "385496   4.845581   -3.837952  2.791040  171.200000  1.511234  14.101810   \n",
       "385497   5.219055   -3.618164  6.078650  176.275387  1.619186   7.160672   \n",
       "385498  15.296118   -3.948083  7.470391   72.200000  1.042840  16.477707   \n",
       "385499   4.794330  -16.178510  1.785699  114.000000  1.394616   4.402023   \n",
       "\n",
       "        negpmax[8]    area[8]     tmax[8]    rms[8]     pmax[9]  negpmax[9]  \\\n",
       "0       -15.625539  13.374258   72.200000  1.211460   99.361264  -56.828006   \n",
       "1       -11.742902  14.334657   71.000000  1.248869   96.062561  -58.803436   \n",
       "2       -11.581955  11.901321   71.800000  1.712700   93.767398  -62.801328   \n",
       "3       -10.409299  12.231570   72.200000  0.825131   89.620438  -62.658493   \n",
       "4       -10.298044  11.949759   71.200000  1.627493  106.109430  -68.653479   \n",
       "...            ...        ...         ...       ...         ...         ...   \n",
       "385495   -4.807355   3.696760  193.200000  0.876277    3.324582   -4.966765   \n",
       "385496   -4.986447  11.568833   72.200000  1.941815   12.819989   -4.160602   \n",
       "385497   -3.944553   4.267343  132.800000  1.612187    3.859982   -5.145389   \n",
       "385498   -4.348218   6.246851   72.158232  1.794087   11.385178   -2.968319   \n",
       "385499  -18.913599   3.972903   62.400000  1.207466    3.848242  -20.433275   \n",
       "\n",
       "          area[9]  tmax[9]    rms[9]   pmax[10]  negpmax[10]   area[10]  \\\n",
       "0       48.422567     72.0  0.971254  42.068393   -19.716336  23.152819   \n",
       "1       47.559857     70.8  1.646606  38.690210   -19.613623  20.574321   \n",
       "2       46.121189     71.6  1.509499  40.337067   -23.637970  19.456946   \n",
       "3       48.821906     72.0  1.945644  37.796774   -21.114725  20.897897   \n",
       "4       49.846171     71.0  1.471771  42.202023   -20.666324  21.795638   \n",
       "...           ...      ...       ...        ...          ...        ...   \n",
       "385495   1.712936     93.2  0.906276   5.018600    -4.641771   1.715207   \n",
       "385496   6.684895     72.2  1.675671  12.100403    -4.664246   8.123401   \n",
       "385497   2.331159     76.4  1.267967   6.587385    -3.648233   9.381399   \n",
       "385498   5.846973     72.2  1.181766  13.214905    -4.522888   8.463049   \n",
       "385499   2.189797    130.2  1.062997   4.959647   -21.246221   3.000378   \n",
       "\n",
       "         tmax[10]   rms[10]   pmax[11]  negpmax[11]   area[11]    tmax[11]  \\\n",
       "0       72.000000  1.285425  12.438458   -18.148151   7.611376   72.200000   \n",
       "1       70.800000  1.236410  12.326212    -5.670920   8.025536  119.600000   \n",
       "2       71.600000  1.973803   9.253250    -4.282883   4.517316   71.800000   \n",
       "3       72.000000  1.224526  10.900876    -5.595096   5.927390   72.200000   \n",
       "4       71.000000  1.604495  13.956659    -5.728705   7.386077   71.000000   \n",
       "...           ...       ...        ...          ...        ...         ...   \n",
       "385495  71.400000  1.467989   5.526794    -6.992345   1.990222  204.400000   \n",
       "385496  72.200000  1.856407  15.208563    -5.161127  11.758268   72.200000   \n",
       "385497  71.247274  1.655136   5.343299    -4.516763   4.862441   71.576952   \n",
       "385498  72.000000  1.647129  13.605057    -5.050461   9.017706   72.000000   \n",
       "385499  71.800000  1.761634   6.934341   -15.145020  18.547925   71.861420   \n",
       "\n",
       "         rms[11]   pmax[12]  negpmax[12]   area[12]   tmax[12]   rms[12]  \\\n",
       "0       0.904157   4.559802   -18.432141   2.288938   38.40000  0.939772   \n",
       "1       1.201039  15.498431    -6.770750  11.107231  119.84105  1.483650   \n",
       "2       1.995394   4.168692    -4.282668   2.504671  141.60000  2.004948   \n",
       "3       1.491610   3.521313    -5.788109   1.350378   70.60000  1.019475   \n",
       "4       1.318873   3.991907    -5.890051   3.002041  109.20000  1.384048   \n",
       "...          ...        ...          ...        ...        ...       ...   \n",
       "385495  1.061959   3.577979    -5.627954   2.159707   53.80000  0.767079   \n",
       "385496  1.330986  15.737668    -4.732547   7.565947   72.20000  1.717499   \n",
       "385497  2.044186   5.385049    -4.829733   3.039965  127.00000  1.266236   \n",
       "385498  2.052866  15.326770    -4.139905  16.555281   72.20000  0.985935   \n",
       "385499  1.224573   5.624060   -18.254765   2.775803  167.40000  2.039344   \n",
       "\n",
       "         pmax[13]  negpmax[13]   area[13]    tmax[13]   rms[13]   pmax[14]  \\\n",
       "0        7.454877   -16.861163   4.191909   72.600000  1.184943   6.611877   \n",
       "1       18.472514    -3.372324  16.620582  119.812512  1.578009  13.802252   \n",
       "2        7.336668    -5.742383  11.792258   71.908212  1.333036   5.940039   \n",
       "3        8.450671    -6.342114   4.496741   72.600000  1.945065   6.434910   \n",
       "4        8.721952    -4.396436   9.127136   71.411535  1.513988   4.483080   \n",
       "...           ...          ...        ...         ...       ...        ...   \n",
       "385495  19.454065    -7.531409  10.650762   71.400000  0.964490   5.842563   \n",
       "385496  17.604636    -5.505725  12.827195   71.500314  1.632497  11.819031   \n",
       "385497  20.783524    -6.318405  13.981320   71.600000  1.944626  10.120659   \n",
       "385498  14.048267    -6.915601  11.846003   71.600000  1.286150  10.754880   \n",
       "385499  21.256503   -17.559171  15.069589   72.000000  0.734442   6.895911   \n",
       "\n",
       "        negpmax[14]   area[14]    tmax[14]   rms[14]    pmax[15]  negpmax[15]  \\\n",
       "0        -17.685799   4.884680  162.800000  1.284969  149.648736   -18.546884   \n",
       "1         -5.154840   8.758870  120.000000  1.093953  148.942977    -4.697864   \n",
       "2         -3.860550   5.340140    6.614830  1.183951  153.494632    -4.584915   \n",
       "3         -5.576315  15.789638   72.195420  1.738998  151.859889    -4.744748   \n",
       "4         -5.361823   3.366542  160.185705  1.323621  137.139115    -5.357361   \n",
       "...             ...        ...         ...       ...         ...          ...   \n",
       "385495    -4.147369   4.551567   71.200000  1.681396  131.786591    -4.857419   \n",
       "385496    -5.125480   4.505713   72.400000  1.227755  122.000994    -3.520840   \n",
       "385497    -3.479907  11.049597   71.373814  1.273724  131.856155    -5.187308   \n",
       "385498    -5.030399   7.560762   71.200000  1.053635  122.657732    -4.574358   \n",
       "385499   -20.049325   3.515742   71.800000  1.589978  119.050219   -22.519223   \n",
       "\n",
       "          area[15]   tmax[15]   rms[15]    pmax[16]  negpmax[16]    area[16]  \\\n",
       "0       146.036298  72.276594  1.196239  607.109118   -36.282996  583.899899   \n",
       "1       171.081604  71.065221  1.534433  630.348007   -39.715988  580.042799   \n",
       "2       137.502422  71.869933  1.010175  613.880342   -40.679678  580.407491   \n",
       "3       135.724871  72.262946  1.283015  600.714957   -43.206601  579.882635   \n",
       "4       147.372754  71.212440  1.480449  609.723785   -43.570892  590.156125   \n",
       "...            ...        ...       ...         ...          ...         ...   \n",
       "385495  153.707394  71.415674  1.932267  581.954264   -39.634247  580.419676   \n",
       "385496  162.981252  71.598409  1.305790  591.334030   -40.229095  589.105579   \n",
       "385497  151.267330  71.605585  2.086888  619.698505   -46.600293  582.079851   \n",
       "385498  161.842151  71.501886  0.932597  597.935632   -43.848615  589.201047   \n",
       "385499  151.665894  72.067806  1.593781  605.837434   -43.600342  583.723657   \n",
       "\n",
       "         tmax[16]   rms[16]    pmax[17]  negpmax[17]    area[17]   tmax[17]  \\\n",
       "0       72.373094  0.374498  614.916861   -39.848523  591.852768  72.331028   \n",
       "1       71.029155  0.403258  624.950701   -41.266681  586.569646  71.089058   \n",
       "2       71.892264  0.568777  596.437125   -42.712286  574.091695  71.943934   \n",
       "3       72.357388  0.255483  591.763739   -50.681940  584.099483  72.333282   \n",
       "4       71.249130  0.413855  606.917023   -49.923819  584.316142  71.242904   \n",
       "...           ...       ...         ...          ...         ...        ...   \n",
       "385495  71.167754  0.714250  614.629732   -47.182980  594.565758  71.359798   \n",
       "385496  71.562414  0.325978  589.602095   -49.995053  588.799525  71.539605   \n",
       "385497  71.420761  0.430833  610.999390   -43.620535  589.163170  71.569655   \n",
       "385498  71.426835  0.474301  611.263138   -49.387009  587.916994  71.466307   \n",
       "385499  71.814597  0.509508  581.580222   -51.947507  582.576141  72.015844   \n",
       "\n",
       "         rms[17]  \n",
       "0       0.405595  \n",
       "1       0.405890  \n",
       "2       0.498019  \n",
       "3       0.336454  \n",
       "4       0.293824  \n",
       "...          ...  \n",
       "385495  0.345872  \n",
       "385496  0.318873  \n",
       "385497  0.301635  \n",
       "385498  0.408242  \n",
       "385499  0.354110  \n",
       "\n",
       "[385500 rows x 92 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATASETPATH = \"./data/DSL_Winter_Project_2024/DSL_Winter_Project_2024/development.csv\"\n",
    "dataset = pd.read_csv(DATASETPATH)\n",
    "\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d19f5589-a4eb-447e-b325-bce2d09644ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateColumnsNames(title, ignore=[]):\n",
    "    out = []\n",
    "    for i in range(0, 18):\n",
    "        if(not i in ignore):\n",
    "            out.append( title + \"[\" + str(i) + \"]\" )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a56b9fa4-f121-479b-bec1-a01734aed374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateColumnsNamesFromIndexes(indexes):\n",
    "    out = []\n",
    "    for index in indexes:\n",
    "        for label in [\"pmax\", \"negpmax\", \"area\", \"tmax\", \"rms\"]:\n",
    "            out.append(label + \"[\" + str(index) + \"]\")\n",
    "    return out\n",
    "\n",
    "regressionTargets = ['x', 'y']\n",
    "noisyIndexes = [0, 7, 12, 15, 16, 17]\n",
    "noisyFeatures= generateColumnsNamesFromIndexes(noisyIndexes)\n",
    "featuresLabels = dataset.columns.drop(np.hstack([regressionTargets, noisyFeatures]))\n",
    "dataset_shuff = dataset.sample(random_state=rs, frac=1)  #shuffle the dataset\n",
    "X_df = dataset_shuff[featuresLabels]\n",
    "Y_df = dataset_shuff[regressionTargets]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b8c3c7-08be-4b0a-a6cb-9a0cfd1d289f",
   "metadata": {},
   "source": [
    "## Train - Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29f490ad-024d-4949-a2d6-34a1184b599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.2\n",
    "test_length = int(len(X_df) * 0.2)\n",
    "train_length = len(X_df) - test_length\n",
    "test_mask = np.array(test_length * [True] + train_length * [False])\n",
    "np.random.shuffle(test_mask)\n",
    "X_test = X_df.values[test_mask, :]\n",
    "Y_test = Y_df.values[test_mask, :]\n",
    "X_train = X_df.values[~test_mask, :]\n",
    "Y_train = Y_df.values[~test_mask, :]\n",
    "\n",
    "#tain-test split on a subset of features\n",
    "X_red_df = X_df[generateColumnsNames(\"area\", ignore=noisyIndexes) + generateColumnsNames(\"pmax\", ignore=noisyIndexes) + generateColumnsNames(\"negpmax\", ignore=noisyIndexes)]\n",
    "X_test_red = X_red_df.values[test_mask, :]\n",
    "X_train_red = X_red_df.values[~test_mask, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46ba872-379c-4c4c-9b28-54fb915f59ea",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7d78b4f-1d76-409b-aa10-179c690db88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0efa14-54b0-4a5e-895f-2a2d55b7c7c6",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c470d2ad-9b23-4aec-b496-e09df211419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euc_dist(Y, Y_pred):\n",
    "    #return np.sqrt(((Y_pred - Y_test)**2).sum(axis=1)).sum(axis=0) / Y_pred.shape[0]\n",
    "    return np.sqrt(((Y - Y_pred)**2).sum(axis=1)).mean()\n",
    "\n",
    "euc_dist_scorer = make_scorer(euc_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd8170ab-5684-4ea9-aff8-927f32a5a374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number: 0. Current parameters: {'activation': 'logistic', 'batch_size': 200, 'hidden_layer_sizes': (400,), 'max_iter': 600, 'solver': 'adam'}\n",
      "score: 4.2639022858849795\n",
      "Iteration number: 1. Current parameters: {'activation': 'logistic', 'batch_size': 200, 'hidden_layer_sizes': (600,), 'max_iter': 600, 'solver': 'adam'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 4.318243531705598\n",
      "Iteration number: 2. Current parameters: {'activation': 'logistic', 'batch_size': 200, 'hidden_layer_sizes': (800,), 'max_iter': 600, 'solver': 'adam'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\marco\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\marco\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 4.400655751036382\n",
      "Iteration number: 3. Current parameters: {'activation': 'logistic', 'batch_size': 200, 'hidden_layer_sizes': (400, 400), 'max_iter': 600, 'solver': 'adam'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\marco\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\marco\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 4.503957988587052\n",
      "Iteration number: 4. Current parameters: {'activation': 'logistic', 'batch_size': 200, 'hidden_layer_sizes': (600, 600), 'max_iter': 600, 'solver': 'adam'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\marco\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\marco\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 4.925231683401544\n",
      "Iteration number: 5. Current parameters: {'activation': 'logistic', 'batch_size': 200, 'hidden_layer_sizes': (800, 800), 'max_iter': 600, 'solver': 'adam'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\marco\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "C:\\Users\\marco\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     14\u001b[0m     reg \u001b[38;5;241m=\u001b[39m MLPRegressor(random_state\u001b[38;5;241m=\u001b[39mrs, early_stopping\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n\u001b[1;32m---> 15\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(\u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_std\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meuc_dist_scorer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean())\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscores[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(scores)\n",
      "File \u001b[1;32m~\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    560\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 562\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32m~\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 309\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:751\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    748\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    750\u001b[0m fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m--> 751\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m \u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    752\u001b[0m score_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m-\u001b[39m fit_time\n\u001b[0;32m    753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n",
      "File \u001b[1;32m~\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:810\u001b[0m, in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[0;32m    808\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test)\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 810\u001b[0m         scores \u001b[38;5;241m=\u001b[39m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[0;32m    814\u001b[0m         \u001b[38;5;66;03m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:136\u001b[0m, in \u001b[0;36m_MultimetricScorer.__call__\u001b[1;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _BaseScorer):\n\u001b[1;32m--> 136\u001b[0m         score \u001b[38;5;241m=\u001b[39m scorer\u001b[38;5;241m.\u001b[39m_score(\n\u001b[0;32m    137\u001b[0m             cached_call, estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mget(name)\u001b[38;5;241m.\u001b[39mscore\n\u001b[0;32m    138\u001b[0m         )\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    140\u001b[0m         score \u001b[38;5;241m=\u001b[39m scorer(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mget(name)\u001b[38;5;241m.\u001b[39mscore)\n",
      "File \u001b[1;32m~\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:353\u001b[0m, in \u001b[0;36m_PredictScorer._score\u001b[1;34m(self, method_caller, estimator, X, y_true, **kwargs)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate predicted target values for X relative to y_true.\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;124;03m    Score function applied to prediction of estimator on X.\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_overlap(\n\u001b[0;32m    346\u001b[0m     message\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    347\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere is an overlap between set kwargs of this scorer instance and\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    351\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m    352\u001b[0m )\n\u001b[1;32m--> 353\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmethod_caller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m scoring_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sign \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_score_func(y_true, y_pred, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscoring_kwargs)\n",
      "File \u001b[1;32m~\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:86\u001b[0m, in \u001b[0;36m_cached_call\u001b[1;34m(cache, estimator, response_method, *args, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m response_method \u001b[38;5;129;01min\u001b[39;00m cache:\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cache[response_method]\n\u001b[1;32m---> 86\u001b[0m result, _ \u001b[38;5;241m=\u001b[39m _get_response_values(\n\u001b[0;32m     87\u001b[0m     estimator, \u001b[38;5;241m*\u001b[39margs, response_method\u001b[38;5;241m=\u001b[39mresponse_method, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m     88\u001b[0m )\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     cache[response_method] \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32m~\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\utils\\_response.py:218\u001b[0m, in \u001b[0;36m_get_response_values\u001b[1;34m(estimator, X, response_method, pos_label)\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response_method \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    213\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should either be a classifier to be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    214\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mused with response_method=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or the response_method \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    215\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Got a regressor with response_method=\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    216\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m         )\n\u001b[1;32m--> 218\u001b[0m     y_pred, pos_label \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_pred, pos_label\n",
      "File \u001b[1;32m~\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1599\u001b[0m, in \u001b[0;36mMLPRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1586\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict using the multi-layer perceptron model.\u001b[39;00m\n\u001b[0;32m   1587\u001b[0m \n\u001b[0;32m   1588\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1596\u001b[0m \u001b[38;5;124;03m    The predicted values.\u001b[39;00m\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1598\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1599\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1603\u001b[0m, in \u001b[0;36mMLPRegressor._predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m   1601\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1602\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Private predict method with optional input validation\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1603\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_pass_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1604\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1605\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m y_pred\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[1;32m~\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:218\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._forward_pass_fast\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    216\u001b[0m     activation \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercepts_[i]\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layers_ \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 218\u001b[0m         \u001b[43mhidden_activation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m output_activation \u001b[38;5;241m=\u001b[39m ACTIVATIONS[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_activation_]\n\u001b[0;32m    220\u001b[0m output_activation(activation)\n",
      "File \u001b[1;32m~\\Documents\\poli\\dataScienceLab\\labs\\dslab\\lib\\site-packages\\sklearn\\neural_network\\_base.py:24\u001b[0m, in \u001b[0;36minplace_logistic\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Simply leave the input array unchanged.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m        and `n_features` is the number of features.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# Nothing to do\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minplace_logistic\u001b[39m(X):\n\u001b[0;32m     25\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the logistic function inplace.\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m        The input data.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     logistic_sigmoid(X, out\u001b[38;5;241m=\u001b[39mX)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"activation\": [\"logistic\", \"tanh\", \"relu\"],\n",
    "    \"solver\" : [\"adam\"],\n",
    "    \"max_iter\": [600],\n",
    "    \"hidden_layer_sizes\": [(400,), (600,), (800,), (400, 400), (600, 600), (800, 800)],\n",
    "    \"batch_size\": [200, 300],\n",
    "}\n",
    "\n",
    "scores = []\n",
    "iter=0\n",
    "for config in ParameterGrid(params):\n",
    "    print(f\"Iteration number: {iter}. Current parameters: {config}\")\n",
    "    iter += 1\n",
    "    reg = MLPRegressor(random_state=rs, early_stopping=False, **config)\n",
    "    scores.append(cross_val_score(reg, X_train_std, Y_train, cv=3, scoring=euc_dist_scorer).mean())\n",
    "    print(f\"score: {scores[-1]}\")\n",
    "plt.plot(scores)\n",
    "plt.show()\n",
    "best_params = list(ParameterGrid(params))[np.argmin(scores)]\n",
    "print(f\"Neural network grid search results. Best params: {best_params}\")\n",
    "\n",
    "#evaluate on best params\n",
    "MLPReg = MLPRegressor(random_state=rs, early_stopping=False, **best_params)\n",
    "MLPReg.fit(X_train_std, Y_train)\n",
    "Y_pred = MLPReg.predict(X_test_std)\n",
    "pd.DataFrame(Y_pred, columns=[\"x\", \"y\"]).plot.scatter(\"x\", \"y\", alpha=0.1, s=2, title=\"Position of predicted points\", xlim=(195, 605), ylim=(195, 605))\n",
    "print(f\"Neural network regression. Euclidean distance score: %.2f \"%euc_dist(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbde010-3d63-4de9-92d2-c9b980f7f742",
   "metadata": {},
   "source": [
    "## Final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb20dd9-b2be-415c-8e2f-54bacbce8fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATIONPATH = \"./data/DSL_Winter_Project_2024/DSL_Winter_Project_2024/evaluation.csv\"\n",
    "evaluation = pd.read_csv(EVALUATIONPATH, index_col=\"Id\")\n",
    "#X_ev = X_ev[generateColumnsNames(\"area\", ignore=noisyIndexes) + generateColumnsNames(\"pmax\", ignore=noisyIndexes)]\n",
    "X_ev = evaluation[featuresLabels]\n",
    "\n",
    "MLPReg.set_params(warm_start=False, verbose=True)\n",
    "finalReg = MLPReg\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X_std = stdScaler.fit_transform(X_df.values)\n",
    "X_ev_std = stdScaler.transform(X_ev.values)\n",
    "\n",
    "finalReg.fit(X_std, Y_df.values)\n",
    "Y_ev = finalReg.predict(X_ev_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb80087-a7ce-4f6b-a04f-c057cbc9a9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLPReg.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3c9ec3-c799-452d-8ca8-bfdedf474ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame()\n",
    "Y_ev_df = pd.DataFrame(Y_ev)\n",
    "display(Y_ev_df)\n",
    "#output['Predicted'] = (Y_ev_df[0]).round().astype(str) + \"|\" + (Y_ev_df[1]).round().astype(str)\n",
    "output['Predicted'] = (Y_ev_df[0]).astype(str) + \"|\" + (Y_ev_df[1]).astype(str)\n",
    "output.to_csv(\"submission10_MLP6.csv\", index_label=\"Id\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
